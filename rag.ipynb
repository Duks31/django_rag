{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list', 'data': [{'id': 'meta-llama/llama-4-scout-17b-16e-instruct', 'object': 'model', 'created': 1743874824, 'owned_by': 'Meta', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'compound-beta', 'object': 'model', 'created': 1740880017, 'owned_by': 'Groq', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'meta-llama/llama-guard-4-12b', 'object': 'model', 'created': 1746743847, 'owned_by': 'Meta', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 1024}, {'id': 'mistral-saba-24b', 'object': 'model', 'created': 1739996492, 'owned_by': 'Mistral AI', 'active': True, 'context_window': 32768, 'public_apps': None, 'max_completion_tokens': 32768}, {'id': 'compound-beta-mini', 'object': 'model', 'created': 1742953279, 'owned_by': 'Groq', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'playai-tts-arabic', 'object': 'model', 'created': 1740682783, 'owned_by': 'PlayAI', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'llama-3.3-70b-versatile', 'object': 'model', 'created': 1733447754, 'owned_by': 'Meta', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 32768}, {'id': 'whisper-large-v3-turbo', 'object': 'model', 'created': 1728413088, 'owned_by': 'OpenAI', 'active': True, 'context_window': 448, 'public_apps': None, 'max_completion_tokens': 448}, {'id': 'deepseek-r1-distill-llama-70b', 'object': 'model', 'created': 1737924940, 'owned_by': 'DeepSeek / Meta', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 131072}, {'id': 'llama-3.1-8b-instant', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 131072}, {'id': 'distil-whisper-large-v3-en', 'object': 'model', 'created': 1693721698, 'owned_by': 'Hugging Face', 'active': True, 'context_window': 448, 'public_apps': None, 'max_completion_tokens': 448}, {'id': 'llama3-70b-8192', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'gemma2-9b-it', 'object': 'model', 'created': 1693721698, 'owned_by': 'Google', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'object': 'model', 'created': 1743877158, 'owned_by': 'Meta', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'llama-guard-3-8b', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'playai-tts', 'object': 'model', 'created': 1740682771, 'owned_by': 'PlayAI', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'qwen-qwq-32b', 'object': 'model', 'created': 1741214760, 'owned_by': 'Alibaba Cloud', 'active': True, 'context_window': 131072, 'public_apps': None, 'max_completion_tokens': 131072}, {'id': 'llama3-8b-8192', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}, {'id': 'whisper-large-v3', 'object': 'model', 'created': 1693721698, 'owned_by': 'OpenAI', 'active': True, 'context_window': 448, 'public_apps': None, 'max_completion_tokens': 448}, {'id': 'allam-2-7b', 'object': 'model', 'created': 1737672203, 'owned_by': 'SDAIA', 'active': True, 'context_window': 4096, 'public_apps': None, 'max_completion_tokens': 4096}]}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.groq.com/openai/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's technology-driven world, and their importance can be understood from several perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models enable computers to process and understand human language quickly, which is essential for real-time applications such as chatbots, virtual assistants, and language translation software. This efficiency allows for smoother and more responsive user interactions.\n",
      "2. **Improved User Experience**: Faster language models lead to reduced latency, which is critical for applications that require prompt responses, such as customer service chatbots, speech recognition systems, and voice-activated interfaces. A faster response time enhances the overall user experience, making it more engaging and satisfying.\n",
      "3. **Increased Productivity**: Fast language models can automate tasks, such as text summarization, sentiment analysis, and content generation, which can save time and effort for professionals, researchers, and content creators. By streamlining these tasks, individuals can focus on higher-value activities, leading to increased productivity.\n",
      "4. **Enhanced Accuracy**: Faster language models can process larger amounts of data, which can lead to improved accuracy in tasks like language translation, speech recognition, and text classification. This increased accuracy can have a significant impact on applications like language translation, where a small error can change the meaning of a sentence entirely.\n",
      "5. **Real-time Analytics**: Fast language models can analyze large volumes of text data in real-time, enabling organizations to gain insights into customer opinions, sentiment, and preferences. This information can be used to inform business decisions, such as product development, marketing strategies, and customer support.\n",
      "6. **Competitive Advantage**: Companies that adopt fast language models can gain a competitive edge over their rivals. By leveraging the power of fast language models, businesses can develop innovative products and services, improve customer engagement, and respond quickly to changing market conditions.\n",
      "7. **Edge Computing**: Fast language models are essential for edge computing applications, where data is processed and analyzed in real-time, reducing latency and bandwidth requirements. This is particularly important for applications like autonomous vehicles, smart homes, and industrial automation.\n",
      "8. **Multi-Modal Interaction**: Fast language models can facilitate multi-modal interaction, where users can interact with devices using voice, text, or gestures. This enables a more natural and intuitive user experience, which is critical for applications like smart homes, wearables, and augmented reality.\n",
      "9. **Accessibility**: Fast language models can improve accessibility for people with disabilities, such as those who rely on speech-to-text or text-to-speech systems. Faster language models can provide more accurate and responsive assistance, enhancing the overall quality of life for these individuals.\n",
      "10. **Future-Proofing**: As language models continue to evolve, fast language models will be essential for future applications, such as human-computer interaction, cognitive architectures, and artificial general intelligence. By developing and deploying fast language models, researchers and developers can lay the foundation for more advanced AI systems.\n",
      "\n",
      "In summary, fast language models are vital for a wide range of applications, from chatbots and virtual assistants to language translation and text analysis. Their importance extends to improving user experience, increasing productivity, and driving innovation, ultimately transforming the way we interact with technology and each other.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
